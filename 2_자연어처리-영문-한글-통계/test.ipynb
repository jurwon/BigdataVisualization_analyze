{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 영문 분석 -> 워드 클라우드로 그리기(시각화)\n",
    "\n",
    "## 샘플 데이터 영문 학술 문서의 제목만 추출, 그 단어의 빈도 분석 시각화 \n",
    "## 데이터 수집 : Big data 키워드로 검색 후, 해당 학술 연구 정보 서비스에서 수집 해보기. \n",
    "## 조합, pandas.concat(), 정제 re 정규식, 기본적인 유효성 체크. \n",
    "## 변환 : word_tokenize(), lower(), \n",
    "## matplotlib.pyplot 이용하기. \n",
    "## 단어 빈도 구해주는 Counter() 이용. \n",
    "\n",
    "## 비정형 빅데이터 분석을 말하고 -> 자연어 처리 (nature language processing )\n",
    "## 자연어 처리 예) 음성, 텍스트 정보 추출. \n",
    "\n",
    "## 단어 빈도를 추출해서, 해당 단어 시각화하기."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 관련 단어 용어 정리 \n",
    "## 텍스트 분석: 자연어 처리와 데이터 마이닝 결합하여 발전되었고, \n",
    "## 비정형 텍스트 데이터에서 정보를 추출하는 분석 방법. \n",
    "## 분석 방법 : 1) 텍스트 분류 2) 텍스트 군집화 3) 감성 분석. \n",
    "\n",
    "## 전처리 : 분석 작업의 정확도를 높이기 위해서 사용할 데이터 정리하고 변환하는 작업. \n",
    "### 수행하는 작업 \n",
    "### 정제 (cleaning): 불필요한 기호, 문자 필터하는 작업, 정규식을 이용해서 작업을 함. \n",
    "### 정규화 ( normallization) : 형태가 다른 단어를 특정의 형태로 변환 작업 , 대문자, 소문자 통합 하는 작업, 의미가 비슷한 단어끼리 통합작업. \n",
    "### 토큰화 (tokenization) : 토큰으로 정하는 기본 단위로 분리 작업. 문장 기준, 단어 기준이 될수 도 있다. \n",
    "### 불용어제거(stopword) : 의미 있는 단어를 추출하기 위해서, 조사, 관사, 접미사, 접두사 등. 제거하는 작업. \n",
    "### 어간 추출(semming) : 단수, 복수, 진행형(시제), 분리하는 작업 \n",
    "### 표제어 추출(lemmatization ): 단어의 기본형 형태로 일반화 하는 작업. \n",
    "### 예) \n",
    "### Gone -> go \n",
    "### am -> be\n",
    "### going -> go \n",
    "\n",
    "## 워드클라우드 : 텍스트 분석에서 빈도를 시각화 할 때 많이 사용됨. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 수집 \n",
    "# 한국교육학술정보원 (KERIS)의 RISS 사이트 \n",
    "# https://www.riss.kr/index.do\n",
    "# Big data 검색해보기.\n",
    "# 한 페이지당 100개씩 내보내기 엑셀 파일 간략 정보 , 반복 10번 \n",
    "# 1000개의 데이터에서 제목만 추출 및 분류 작업하기. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 준비 작업. \n",
    "# 제목 컬럼 빈도 분석 해보기. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wordcloud\n",
      "  Obtaining dependency information for wordcloud from https://files.pythonhosted.org/packages/bf/a0/b8fa5f2d7147a7675e2cab99108f7d8d524b67481f81f289cdb2b64ed1ab/wordcloud-1.9.3-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading wordcloud-1.9.3-cp312-cp312-win_amd64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\na\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wordcloud) (1.26.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\na\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wordcloud) (10.1.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\na\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wordcloud) (3.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\na\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->wordcloud) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\na\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->wordcloud) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\na\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->wordcloud) (4.46.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\na\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->wordcloud) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\na\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->wordcloud) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\na\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->wordcloud) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\na\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\na\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Downloading wordcloud-1.9.3-cp312-cp312-win_amd64.whl (301 kB)\n",
      "   ---------------------------------------- 0.0/301.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/301.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/301.4 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/301.4 kB ? eta -:--:--\n",
      "   --- ----------------------------------- 30.7/301.4 kB 325.1 kB/s eta 0:00:01\n",
      "   ----- --------------------------------- 41.0/301.4 kB 326.8 kB/s eta 0:00:01\n",
      "   ----- --------------------------------- 41.0/301.4 kB 326.8 kB/s eta 0:00:01\n",
      "   -------------- ----------------------- 112.6/301.4 kB 409.6 kB/s eta 0:00:01\n",
      "   ------------------- ------------------ 153.6/301.4 kB 458.0 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 256.0/301.4 kB 682.7 kB/s eta 0:00:01\n",
      "   -------------------------------------- 301.4/301.4 kB 744.6 kB/s eta 0:00:00\n",
      "Installing collected packages: wordcloud\n",
      "Successfully installed wordcloud-1.9.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.0/1.5 MB 435.7 kB/s eta 0:00:04\n",
      "     - -------------------------------------- 0.0/1.5 MB 393.8 kB/s eta 0:00:04\n",
      "     -------- ------------------------------- 0.3/1.5 MB 2.3 MB/s eta 0:00:01\n",
      "     ----------------------- ---------------- 0.9/1.5 MB 4.7 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 1.4/1.5 MB 6.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.5/1.5 MB 6.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.5/1.5 MB 4.8 MB/s eta 0:00:00\n",
      "Collecting click (from nltk)\n",
      "  Obtaining dependency information for click from https://files.pythonhosted.org/packages/00/2e/d53fa4befbf2cfa713304affc7ca780ce4fc1fd8710527771b58311a3229/click-8.1.7-py3-none-any.whl.metadata\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting joblib (from nltk)\n",
      "  Obtaining dependency information for joblib from https://files.pythonhosted.org/packages/10/40/d551139c85db202f1f384ba8bcf96aca2f329440a844f924c8a0040b6d02/joblib-1.3.2-py3-none-any.whl.metadata\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Obtaining dependency information for regex>=2021.8.3 from https://files.pythonhosted.org/packages/d3/10/6f2d5f8635d7714ad97ce6ade7a643358c4f3e45cde4ed12b7150734a8f3/regex-2023.10.3-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading regex-2023.10.3-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.0/42.0 kB 2.0 MB/s eta 0:00:00\n",
      "Collecting tqdm (from nltk)\n",
      "  Obtaining dependency information for tqdm from https://files.pythonhosted.org/packages/00/e5/f12a80907d0884e6dff9c16d0c0114d81b8cd07dc3ae54c5e962cc83037e/tqdm-4.66.1-py3-none-any.whl.metadata\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.6/57.6 kB 3.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\na\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk) (0.4.6)\n",
      "Downloading regex-2023.10.3-cp312-cp312-win_amd64.whl (268 kB)\n",
      "   ---------------------------------------- 0.0/269.0 kB ? eta -:--:--\n",
      "   ---------------------------- ----------- 194.6/269.0 kB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 269.0/269.0 kB 4.2 MB/s eta 0:00:00\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "   ---------------------------------------- 0.0/97.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 97.9/97.9 kB 5.5 MB/s eta 0:00:00\n",
      "Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "   ---------------------------------------- 0.0/302.2 kB ? eta -:--:--\n",
      "   ---------------------------------------  297.0/302.2 kB 9.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 302.2/302.2 kB 4.7 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.3/78.3 kB 4.5 MB/s eta 0:00:00\n",
      "Installing collected packages: tqdm, regex, joblib, click, nltk\n",
      "Successfully installed click-8.1.7 joblib-1.3.2 nltk-3.8.1 regex-2023.10.3 tqdm-4.66.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "# import nltk\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 관련 패키지들 임포트 하기. \n",
    "import pandas as pd \n",
    "# 경로 이름 지정해서 파일 처리할 때 사용하는 도구\n",
    "import glob \n",
    "# 정규 표현식에 사용하는 도구 \n",
    "import re \n",
    "# 2차원 리스트를 -> 1차원 리스트로 차원 축소시 사용하는 도구 \n",
    "from functools import reduce\n",
    "# 자연어 처리 패키지 중에서, 단어 토큰화 작업.\n",
    "from nltk.tokenize import word_tokenize\n",
    "# 불용어 처리 작업. \n",
    "from nltk.corpus import stopwords \n",
    "# 표제어 추출 \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "# 단어의 빈도를 추출하는 도구. \n",
    "from collections import Counter \n",
    "import matplotlib.pyplot as plt\n",
    "# 단어의 빈도수를 시각화하는 도구, 빈도가 높을수록 글자 크기가 커짐. \n",
    "from wordcloud import STOPWORDS, WordCloud \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>번호</th>\n",
       "      <th>제목</th>\n",
       "      <th>저자</th>\n",
       "      <th>출판사</th>\n",
       "      <th>출판일</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>`Big Data': A Whole Yotta Bytes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>CONGRESSIONAL QUARTERLY INC</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Big Data: A Normal Accident Waiting to Happen?</td>\n",
       "      <td>Nunan, D.; Di Domenico, M.</td>\n",
       "      <td>Springer Science + Business Media</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Data-Driven Authoritarianism: Non-democracies ...</td>\n",
       "      <td>Kabanov, Yury; Karyagin, Mikhail</td>\n",
       "      <td>Springer</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>Big Data. Experts discuss customer data treatment</td>\n",
       "      <td>Cuddeford-Jones, M.</td>\n",
       "      <td>CENTAUR MEDIA PLC</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>Big Data: You Are Adding To ... and Using It</td>\n",
       "      <td>Makela,  Carole J.</td>\n",
       "      <td>American Association of Family and Consumer Sc...</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>NaN</td>\n",
       "      <td>96</td>\n",
       "      <td>Handling big data: research challenges and fut...</td>\n",
       "      <td>Anagnostopoulos, I.; Zeadally, S.; Exposito, E.</td>\n",
       "      <td>Springer Science + Business Media</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>NaN</td>\n",
       "      <td>97</td>\n",
       "      <td>A Big Data-based Workers Behavior Observation ...</td>\n",
       "      <td>Guo, Shengyu; Luo, Hanbin; Yong, Li</td>\n",
       "      <td>Elsevier Science B.V., Amsterdam</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>NaN</td>\n",
       "      <td>98</td>\n",
       "      <td>A big data-driven root cause analysis system: ...</td>\n",
       "      <td>Ma, Qiuping; Li, Hongyan; Thorstenson, Anders</td>\n",
       "      <td>Elsevier Science B.V., Amsterdam.</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>Utilizing ``Big Data'' Modeling for Evaluating...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Connexion International Media</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>Integrating \"big data\" into aquatic ecology: c...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>John Wiley &amp; Co Ltd</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0   번호                                                 제목  \\\n",
       "0          NaN    1                    `Big Data': A Whole Yotta Bytes   \n",
       "1          NaN    2     Big Data: A Normal Accident Waiting to Happen?   \n",
       "2          NaN    3  Data-Driven Authoritarianism: Non-democracies ...   \n",
       "3          NaN    4  Big Data. Experts discuss customer data treatment   \n",
       "4          NaN    5       Big Data: You Are Adding To ... and Using It   \n",
       "..         ...  ...                                                ...   \n",
       "95         NaN   96  Handling big data: research challenges and fut...   \n",
       "96         NaN   97  A Big Data-based Workers Behavior Observation ...   \n",
       "97         NaN   98  A big data-driven root cause analysis system: ...   \n",
       "98         NaN   99  Utilizing ``Big Data'' Modeling for Evaluating...   \n",
       "99         NaN  100  Integrating \"big data\" into aquatic ecology: c...   \n",
       "\n",
       "                                                 저자  \\\n",
       "0                                           unknown   \n",
       "1                        Nunan, D.; Di Domenico, M.   \n",
       "2                  Kabanov, Yury; Karyagin, Mikhail   \n",
       "3                               Cuddeford-Jones, M.   \n",
       "4                                Makela,  Carole J.   \n",
       "..                                              ...   \n",
       "95  Anagnostopoulos, I.; Zeadally, S.; Exposito, E.   \n",
       "96              Guo, Shengyu; Luo, Hanbin; Yong, Li   \n",
       "97    Ma, Qiuping; Li, Hongyan; Thorstenson, Anders   \n",
       "98                                          unknown   \n",
       "99                                          unknown   \n",
       "\n",
       "                                                  출판사   출판일  \n",
       "0                         CONGRESSIONAL QUARTERLY INC  2012  \n",
       "1                   Springer Science + Business Media  2017  \n",
       "2                                            Springer  2018  \n",
       "3                                   CENTAUR MEDIA PLC  2013  \n",
       "4   American Association of Family and Consumer Sc...  2016  \n",
       "..                                                ...   ...  \n",
       "95                  Springer Science + Business Media  2016  \n",
       "96                   Elsevier Science B.V., Amsterdam  2015  \n",
       "97                  Elsevier Science B.V., Amsterdam.  2021  \n",
       "98                      Connexion International Media  2014  \n",
       "99                                John Wiley & Co Ltd  2017  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 조합(병합)하기. \n",
    "# 현재 폴더 내부에 있는 , 받았던 엑셀 파일명 10개를 선택하기. \n",
    "all_files = glob.glob(\"./myCabinetExcelData*.xls\")\n",
    "all_files\n",
    "\n",
    "# 엑셀 파일 읽어서 -> 데이터 프레임 (표형태) 변환 ->특정 리스트에 담아두기 \n",
    "# 임시로 저장할 리스트 변수 \n",
    "all_files_data = []\n",
    "\n",
    "# all_files 에 담겨진 엑셀 파일의 위치가 들어있고, \n",
    "# 해당 위치의 엑셀 파일을 읽어서, 데이터 프레임 표 형태로 변환하기. \n",
    "# 임시 리스트에 담기. \n",
    "for file in all_files:\n",
    "  # 해당 엑셀 파일의 위치의 물리 파일 읽기\n",
    "  data_frame = pd.read_excel(file)\n",
    "  # 임시 리스트에 담기. \n",
    "  all_files_data.append(data_frame)\n",
    "\n",
    "# 샘플 확인 해보기., 첫번째 요소 확인 해보기. \n",
    "# all_files_data = [엑셀1,엑셀2,엑셀3,...엑셀10]\n",
    "all_files_data[0]\n",
    "\n",
    "# 오류 발생, 모듈 미설 : xlrd\n",
    "# cmd -> pip install xlrd "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
